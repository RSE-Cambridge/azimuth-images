#!/usr/bin/env python3

#####
# This script purges defunct images from S3
#
# The images that we want to keep are:
#
#   1. Images from the latest commit to main, failed or not
#   2. Images from the latest commit to main that built successfully - usually the same as 1, hopefully
#   3. Images from commits that correspond to tags
#####

import argparse
import json
import os

import boto3
import requests


class GitHubClient:
    API_URL = "https://api.github.com"

    def __init__(self, token, repo):
        self.session = requests.Session()
        self.session.headers["Content-Type"] = "application/json"
        if token:
            self.session.headers["Authorization"] = f"Bearer {token}"
        self.repo = repo

    def _one(self, url, **kwargs):
        response = self.session.get(url, **kwargs)
        response.raise_for_status()
        return response.json()

    def _iterate(self, url, **kwargs):
        # Iterates over a collection, with pagination
        while url:
            response = self.session.get(url, **kwargs)
            response.raise_for_status()
            yield from response.json()
            url = response.links.get("next", {}).get("url")

    def latest_commits(self):
        """
        Returns a tuple of (latest commit, latest commit that built successfully).
        """
        commits_url = f"{self.API_URL}/repos/{self.repo}/commits"
        default_branch = self._one(f"{self.API_URL}/repos/{self.repo}")["default_branch"]
        latest_commit = None
        latest_successful_commit = None
        for commit in self._iterate(commits_url, params = {"sha": default_branch}):
            if latest_commit is None:
                latest_commit = commit["sha"]
            # Get the check suite that corresponds to GitHub actions
            try:
                check_suite = next(
                    cs
                    for cs in self._one(f"{commit['url']}/check-suites")["check_suites"]
                    if cs["app"]["slug"] == "github-actions"
                )
            except StopIteration:
                pass
            else:
                # If it was successful, we are done
                status, conclusion = check_suite["status"], check_suite["conclusion"]
                if status == "completed" and conclusion == "success":
                    latest_successful_commit = commit["sha"]
                    break
        return latest_commit, latest_successful_commit

    def tagged_commits(self):
        """
        Returns a mapping of commit shas to the associated tags.
        """
        tagged_commits = {}
        for tag in self._iterate(f"{self.API_URL}/repos/{self.repo}/tags"):
            tagged_commits.setdefault(tag["commit"]["sha"], []).append(tag["name"])
        return tagged_commits


class S3Bucket:
    def __init__(self, endpoint, access_key, secret_key, bucket):
        self.s3 = boto3.client(
            "s3",
            endpoint_url = f"https://{endpoint}",
            aws_access_key_id = access_key,
            aws_secret_access_key = secret_key
        )
        self.bucket = bucket

    def list_keys(self):
        """
        Iterates over the keys in a bucket, respecting pagination if required.
        """
        token = None
        while True:
            params = {"Bucket": self.bucket}
            if token:
                params["ContinuationToken"] = token
            next_objects = self.s3.list_objects_v2(**params)
            for object in next_objects["Contents"]:
                yield object["Key"]
            if next_objects["IsTruncated"]:
                token = next_objects["NextContinuationToken"]
            else:
                break

    def fetch_key(self, key):
        """
        Fetches the data for a key.
        """
        return self.s3.get_object(Bucket = self.bucket, Key = key)["Body"].read()

    def delete_key(self, key):
        """
        Deletes a key in the bucket.
        """
        self.s3.delete_object(Bucket = self.bucket, Key = key)


def argparse_add_argument_with_envvar(parser, arg, envvar, **kwargs):
    envvar_value = os.environ.get(envvar) or None
    if envvar_value is not None:
        kwargs.update(default = envvar_value, required = False)
    parser.add_argument(arg, **kwargs)


def main():
    parser = argparse.ArgumentParser(description = "Purges defunct images from S3.")
    argparse_add_argument_with_envvar(
        parser,
        "--s3-host",
        "S3_HOST",
        help = "The S3 host to use.",
        required = True
    )
    argparse_add_argument_with_envvar(
        parser,
        "--s3-access-key",
        "S3_ACCESS_KEY",
        help = "The S3 access key to use.",
        required = True
    )
    argparse_add_argument_with_envvar(
        parser,
        "--s3-secret-key",
        "S3_SECRET_KEY",
        help = "The S3 secret key to use.",
        required = True
    )
    argparse_add_argument_with_envvar(
        parser,
        "--s3-bucket",
        "S3_BUCKET",
        help = "The S3 bucket to use.",
        required = True
    )
    argparse_add_argument_with_envvar(
        parser,
        "--github-token",
        "GITHUB_TOKEN",
        help = "The GitHub token to use."
    )
    argparse_add_argument_with_envvar(
        parser,
        "--github-repository",
        "GITHUB_REPOSITORY",
        help = "The name of the GitHub repository."
    )
    args = parser.parse_args()

    # Initialise the S3 client
    print("[INFO ] initialising S3 client")
    s3 = S3Bucket(args.s3_host, args.s3_access_key, args.s3_secret_key, args.s3_bucket)

    print("[INFO ] initialising GitHub client")
    gh = GitHubClient(args.github_token, args.github_repository)

    print("[INFO ] fetching latest commit info")
    latest_commit, latest_successful_commit = gh.latest_commits()
    print(f"[INFO ]   latest -> {latest_commit}")
    print(f"[INFO ]   latest with successful build -> {latest_successful_commit}")

    print("[INFO ] fetching tagged commits")
    tagged_commits = gh.tagged_commits()
    for commit, tags in tagged_commits.items():
        for tag in tags:
            print(f"[INFO ]   {tag} -> {commit}")

    # Work out which keys we want to purge
    # Start with all of the keys, then remove manifest files, images and cosign bundles
    # for the commits that we want to keep
    print("[INFO ] fetching current S3 keys")
    purge_keys = set(s3.list_keys())
    initial_key_count = len(purge_keys)
    print(f"[INFO ]   found {initial_key_count} keys")

    manifest_keys = [k for k in purge_keys if k.endswith(".manifest")]
    for manifest_key in manifest_keys:
        print(f"[INFO ] processing {manifest_key}")
        manifest_commit = manifest_key.removesuffix(".manifest")

        if manifest_commit == latest_commit:
            print("[INFO ]   manifest is for latest commit - keeping")
        elif manifest_commit == latest_successful_commit:
            print("[INFO ]   manifest is for latest successful build - keeping")
        elif manifest_commit in tagged_commits:
            tag = tagged_commits[manifest_commit][0]
            print(f"[INFO ]   manifest corresponds to tag {tag} - keeping")
        else:
            print(f"[WARN]   manifest and corresponding images and bundles will be purged")
            continue

        print("[INFO ]   removing manifest files from keys to purge")
        purge_keys.discard(manifest_key)
        for image in json.loads(s3.fetch_key(manifest_key)).values():
            purge_keys.discard(f"{image['name']}.qcow2")
            purge_keys.discard(f"{image['name']}.cosign.bundle")

    print(f"[INFO ] keeping {initial_key_count - len(purge_keys)} keys")

    print(f"[INFO ] purging {len(purge_keys)} keys")
    for key in purge_keys:
        print(f"[INFO ]   deleting {key}")
        s3.delete_key(key)


if __name__ == "__main__":
    main()
